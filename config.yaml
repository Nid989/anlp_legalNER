BATCH_SIZE: 32
MAX_EPOCHS: 10
MAX_SEQUENCE_LEN: 256
LEARNING_RATE: 1.0e-4
WEIGHT_DECAY: 1.0e-4
EARLY_STOPPING_THRESHOLD: 5

SOURCE_COLUMN: "tokens"
TARGET_COLUMN: "BIO_tags"
# "BIO_tags" or "BIOES_tags"

MODEL_CHECKPOINT: "xlm-roberta-base"
# distilbert-base-uncased 
# law-ai/InLegalBERT
# xlm-roberta-base
# roberta-base
VERSION: "v6" # Transformer Encoder + Linear Chain CRF
# v1 - Regular Finetunining on judgement data
# v2 - Regular Finetuning with weighted CrossEntropyLoss on judgement data
# v3 - Regular Finetuning with BIOES tagging on judgement data
# v4 - Regualr Finetuning on preamble data
# v5 - Dual Finetuning, preamble and judgement data
# v6 - Regular Finetuning extended with CRF (Conditional Random Fields)
EXTRACT_FORM: "judgement"
# "judgement" or "preamble"
USE_CRF: True # Conditional Random Fields 


PATH_TO_DATA_DIR: "./data" # path to data directory
PATH_TO_CLASS_LABELS: "./data/judgement_class_labels.pkl" # TODO: add preamble file
PATH_TO_RESULT_OUTPUT_DIR: "./results/" # path to results directory with `./results/val/` and `./results/test/` sub-directories
PATH_TO_MODEL_OUTPUT_DIR: "./model_checkpoints/" # path to `trained (saved)` models directory

